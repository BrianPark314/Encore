{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b8ad16-714a-41bb-aa29-4943dc7fe851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.7.5-py3-none-macosx_10_15_x86_64.macosx_11_0_x86_64.macosx_12_0_x86_64.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Users/Shark/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages (from xgboost) (1.24.2)\n",
      "Requirement already satisfied: scipy in /Users/Shark/opt/anaconda3/envs/torch-gpu/lib/python3.8/site-packages (from xgboost) (1.10.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.7.5\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0c53bd7-9c1b-4965-9608-4af4b31bbfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#My solution to Kaggle Titanic Machine Learning from Disaster Challenge\n",
    "#We have to predict survival for passengers onboard rms Titanic using various features describing passengers\n",
    "\n",
    "#The stuff that we are going to need. \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd    #Dataframe library to manipulate data\n",
    "import numpy as np      \n",
    "import re  #We'll be using regular expressions to extract the titles from people's names. Like Mr, Mrs, Count etc\n",
    "#from sklearn.model_selection.cross_validate import KFold   #for k-fold cross-validation\n",
    "#from sklearn.model_selection.cross_validate import cross_validate as cv      #cross-validation\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost \n",
    "from sklearn.model_selection import GridSearchCV   #Support for Hyper-parameter Tuning\n",
    "\n",
    "\n",
    "#Kaggle provides us with two files. train.csv for training our classifier and test.csv \n",
    "#for generating submissions. We read the data in two seperate pandas dataframes\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "#Make a copy of test for later use. \n",
    "test_orig = test[:]\n",
    "\n",
    "#In order to avoid duplication of code owing to applying same operations to both dataframes\n",
    "#we combine the test and train dataframes into one. We'll split them later at time of training.\n",
    "seperator = train.shape[0] #get the length of training data to slie the combined data frame later\n",
    "frames = [train, test]\n",
    "titanic = pd.concat(frames)\n",
    "\n",
    "#cabin has too many missing values. Isn't very important to survial, so we drop it.\n",
    "titanic.drop([\"cabin\"], axis = 1, inplace = True)\n",
    "\n",
    "#Senisble imputation of missing fare values\n",
    "median_fare = titanic.loc[(titanic[\"pclass\"] == 3) & (titanic[\"embarked\"] == \"S\") & (titanic[\"age\"] >= 55)].dropna()[\"fare\"].median()\n",
    "titanic[\"fare\"] = titanic[\"fare\"].fillna(median_fare)\n",
    "\n",
    "def get_title(name):\n",
    "    \"\"\"\n",
    "    Use a regular expression to search for a title.  titles always consist of\n",
    "    capital and lowercase letters, and end with a period.\n",
    "    \n",
    "    Takes a name as input and returns the title string as output\n",
    "    \"\"\"\n",
    "\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "titanic[\"title\"] = titanic[\"name\"].apply(get_title)  #We dropped \"name\" earlier. So, we use original data.\n",
    "\n",
    "#Condense the title into smaller, and more meaningful categories.\n",
    "title_Dictionary = {\n",
    "                        \"Capt\":       \"Officer\",\n",
    "                        \"Col\":        \"Officer\",\n",
    "                        \"Major\":      \"Officer\",\n",
    "                        \"Jonkheer\":   \"Royal\",\n",
    "                        \"Don\":        \"Royal\",\n",
    "                        \"Sir\" :       \"Royal\",\n",
    "                        \"Dr\":         \"Officer\",\n",
    "                        \"Rev\":        \"Officer\",\n",
    "                        \"Countess\":   \"Royal\",\n",
    "                        \"Dona\":       \"Royal\",\n",
    "                        \"Mme\":        \"Mrs\",\n",
    "                        \"Mlle\":       \"Miss\",\n",
    "                        \"Ms\":         \"Mrs\",\n",
    "                        \"Mr\" :        \"Mr\",\n",
    "                        \"Mrs\" :       \"Mrs\",\n",
    "                        \"Miss\" :      \"Miss\",\n",
    "                        \"Master\" :    \"Master\",\n",
    "                        \"Lady\" :      \"Royal\"\n",
    "\n",
    "                        }\n",
    "\n",
    "def titlemap(x):\n",
    "    return title_Dictionary[x]\n",
    "\n",
    "\n",
    "titanic[\"title\"] = titanic[\"title\"].apply(titlemap)\n",
    "\n",
    "#Fill in the missing age values by categorising the data and imputing the missing age values \n",
    "#in a particular category by the median age of that category.\n",
    "#We could replace the age by the median but that would rob our dataset of precious variance \n",
    "#which is important in training our classifier to perform better.\n",
    "\n",
    "def fillages(row):\n",
    "    if not(np.isnan(row['age'])):\n",
    "        return row['age']\n",
    "    \n",
    "    if row['gender']=='female' and row['pclass'] == 1:\n",
    "        if row['title'] == 'Miss':\n",
    "            return 30\n",
    "        elif row['title'] == 'Mrs':\n",
    "            return 45\n",
    "        elif row['title'] == 'Officer':\n",
    "            return 49\n",
    "        elif row['title'] == 'Royalty':\n",
    "            return 39\n",
    "\n",
    "    elif row['gender']=='female' and row['pclass'] == 2:\n",
    "        if row['title'] == 'Miss':\n",
    "            return 20\n",
    "        elif row['title'] == 'Mrs':\n",
    "            return 30\n",
    "\n",
    "    elif row['gender']=='female' and row['pclass'] == 3:\n",
    "        if row['title'] == 'Miss':\n",
    "            return 18\n",
    "        elif row['title'] == 'Mrs':                \n",
    "            return 31\n",
    "\n",
    "    elif row['gender']=='male' and row['pclass'] == 1:\n",
    "        if row['title'] == 'Master':\n",
    "            return 6\n",
    "        elif row['title'] == 'Mr':\n",
    "            return 41.5\n",
    "        elif row['title'] == 'Officer':\n",
    "            return 52\n",
    "        elif row['title'] == 'Royalty':\n",
    "            return 40\n",
    "\n",
    "    elif row['gender']=='male' and row['pclass'] == 2:\n",
    "        if row['title'] == 'Master':\n",
    "            return 2\n",
    "        elif row['title'] == 'Mr':\n",
    "            return 30\n",
    "        elif row['title'] == 'Officer':\n",
    "                return 41.5\n",
    "\n",
    "    elif row['gender']=='male' and row['pclass'] == 3:\n",
    "        if row['title'] == 'Master':\n",
    "            return 6\n",
    "        elif row['title'] == 'Mr':\n",
    "            return 26\n",
    "        \n",
    "titanic[\"age\"] = titanic.apply(fillages, axis = 1)\n",
    "\n",
    "#a Rare title indicates towards a higher chances of survival and hence, more chnaces or survival\n",
    "#We denote Rare titles by 1 and The common ones by 0\n",
    "def isRare(title):\n",
    "    if title == \"Mr\" or title == \"Mrs\" or title == \"Master\" or title == \"Miss\":\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "titanic[\"title\"] = titanic[\"title\"].apply(isRare)\n",
    "\n",
    "#Combing Siblings, Spouses, Parents or children onboard to a single Family variable\n",
    "titanic[\"Family\"] = titanic[\"parch\"] + titanic[\"sibsp\"]\n",
    "\n",
    "#Being a child improves your chances of survival. \n",
    "titanic[\"Child\"] = 0\n",
    "titanic.loc[titanic[\"age\"] <= 18, \"Child\"] = 1\n",
    "\n",
    "\n",
    "#gender is non-numeric data which can't be handled by our classifier. \n",
    "titanic.loc[titanic[\"gender\"] == \"male\", \"gender\"] = 0    #set male to 0 and female to 1\n",
    "titanic.loc[titanic[\"gender\"] == \"female\", \"gender\"] =1\n",
    "\n",
    "titanic[\"gender\"] = titanic[\"gender\"].astype(int)\n",
    "\n",
    "\n",
    "#embarked is non-numeric data. Therefore we are going to build a couple of categorical variables to\n",
    "#represent embarked\n",
    "titanic[\"Q\"] = 0\n",
    "titanic.loc[titanic[\"embarked\"] == \"Q\", \"Q\"] = 1\n",
    "\n",
    "titanic[\"S\"] = 0\n",
    "titanic.loc[titanic[\"embarked\"] == \"S\", \"S\"] = 1\n",
    "\n",
    "# predictors = [\"age\", \"Q\", \"S\", \"fare\", \"pclass\", \"gender\", \"Family\", \"title\", \"Child\"] 0.7655\n",
    "\n",
    "#The predictors that we are going to use\n",
    "predictors = [\"Q\", \"S\", \"fare\", \"pclass\", \"gender\", \"Family\", \"title\", \"Child\"]\n",
    "\n",
    "#Break the combined data set into test and train data\n",
    "target = titanic[\"survived\"].iloc[:seperator]\n",
    "train = titanic[predictors][:seperator]\n",
    "test = titanic[predictors][seperator:]\n",
    "\n",
    "\n",
    "#Build an ensemble of classifiers. Hyper-parameters chosen through cross validation\n",
    "xgb = xgboost.XGBClassifier(learning_rate = 0.05, n_estimators=500);\n",
    "svmc = svm.SVC(C = 5, probability = True)\n",
    "\n",
    "#fit the data\n",
    "xgb.fit(train, target)\n",
    "svmc.fit(train, target)\n",
    "\n",
    "xgb_preds = xgb.predict_proba(test).transpose()[1]\n",
    "svmc_preds = svmc.predict_proba(test).transpose()[1]\n",
    "\n",
    "#Assign different weightages to the classifiers\n",
    "ensemble_preds = xgb_preds*0.75 + svmc_preds*0.25\n",
    "\n",
    "for x in range(len(ensemble_preds)):\n",
    "    if ensemble_preds[x] >= 0.5:\n",
    "        ensemble_preds[x] = 1\n",
    "    else:\n",
    "        ensemble_preds[x] = 0\n",
    "\n",
    "\n",
    "\n",
    "results  = ensemble_preds.astype(int)\n",
    "\n",
    "#Generate the final submission file.\n",
    "submission = pd.DataFrame({\"passengerid\": test_orig[\"passengerid\"], \"survived\": results}) \n",
    "submission.to_csv(\"data/kaggle1.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c8cb3-7a54-45c9-8b9b-b459af255113",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
